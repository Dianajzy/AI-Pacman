{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda6a96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:35.811874Z",
     "iopub.status.busy": "2022-04-14T02:15:35.810358Z",
     "iopub.status.idle": "2022-04-14T02:15:35.819972Z",
     "shell.execute_reply": "2022-04-14T02:15:35.819470Z",
     "shell.execute_reply.started": "2022-04-13T22:02:18.003539Z"
    },
    "papermill": {
     "duration": 0.022067,
     "end_time": "2022-04-14T02:15:35.820101",
     "exception": false,
     "start_time": "2022-04-14T02:15:35.798034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PATH = \"/kaggle/input/tsp-cv\"\n",
    "PATH_TRAIN = os.path.join(PATH, \"train.csv\")\n",
    "PATH_TEST = os.path.join(PATH, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced85ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:35.841084Z",
     "iopub.status.busy": "2022-04-14T02:15:35.840464Z",
     "iopub.status.idle": "2022-04-14T02:15:42.980011Z",
     "shell.execute_reply": "2022-04-14T02:15:42.980413Z",
     "shell.execute_reply.started": "2022-04-13T22:02:31.393080Z"
    },
    "papermill": {
     "duration": 7.15245,
     "end_time": "2022-04-14T02:15:42.980556",
     "exception": false,
     "start_time": "2022-04-14T02:15:35.828106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.6.2\n",
      "Keras Version: 2.6.0\n",
      "\n",
      "Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n",
      "Pandas 1.3.5\n",
      "Scikit-Learn 1.0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:15:41.155488: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-14 02:15:41.211513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:41.292005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:41.292751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:42.964543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:42.965399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:42.966054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:42.966680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() \\\n",
    "      else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2422b162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:43.003839Z",
     "iopub.status.busy": "2022-04-14T02:15:43.003225Z",
     "iopub.status.idle": "2022-04-14T02:15:43.121566Z",
     "shell.execute_reply": "2022-04-14T02:15:43.122157Z",
     "shell.execute_reply.started": "2022-04-13T22:03:32.369076Z"
    },
    "papermill": {
     "duration": 0.132904,
     "end_time": "2022-04-14T02:15:43.122344",
     "exception": false,
     "start_time": "2022-04-14T02:15:42.989440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 14416\n",
      "Validate size: 1602\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)\n",
    "\n",
    "df_train['filename'] = df_train.id.astype(str) + \".jpg\"\n",
    "df_test['filename'] = df_test.id.astype(str) + \".jpg\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train_cut, df_validate_cut = train_test_split(df_train, test_size=0.1, random_state = 42)\n",
    "print(f\"Training size: {len(df_train_cut)}\")\n",
    "print(f\"Validate size: {len(df_validate_cut)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abf4a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:43.148402Z",
     "iopub.status.busy": "2022-04-14T02:15:43.147585Z",
     "iopub.status.idle": "2022-04-14T02:15:48.304496Z",
     "shell.execute_reply": "2022-04-14T02:15:48.304063Z",
     "shell.execute_reply.started": "2022-04-13T22:03:36.802528Z"
    },
    "papermill": {
     "duration": 5.172913,
     "end_time": "2022-04-14T02:15:48.304636",
     "exception": false,
     "start_time": "2022-04-14T02:15:43.131723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14416 validated image filenames.\n",
      "Found 1602 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip=True,\n",
    "  #vertical_flip=True,\n",
    "  fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train_cut,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"distance\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=32, # Keeping the training batch size small USUALLY increases performance\n",
    "        class_mode='raw')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_validate_cut,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"distance\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=256, # Make the validation batch size as large as you have memory for\n",
    "        class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052f6527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:48.329544Z",
     "iopub.status.busy": "2022-04-14T02:15:48.328774Z",
     "iopub.status.idle": "2022-04-14T02:15:49.512347Z",
     "shell.execute_reply": "2022-04-14T02:15:49.512783Z",
     "shell.execute_reply.started": "2022-04-13T22:03:45.990488Z"
    },
    "papermill": {
     "duration": 1.198504,
     "end_time": "2022-04-14T02:15:49.512947",
     "exception": false,
     "start_time": "2022-04-14T02:15:48.314443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:15:48.365814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.366691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.367339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.368217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.368876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.369484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.370153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.370781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:15:48.371356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=False, weights=None, input_tensor=input_tensor,\n",
    "    input_shape=None)\n",
    "\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2766b6ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:49.539444Z",
     "iopub.status.busy": "2022-04-14T02:15:49.538598Z",
     "iopub.status.idle": "2022-04-14T02:15:49.570339Z",
     "shell.execute_reply": "2022-04-14T02:15:49.569943Z",
     "shell.execute_reply.started": "2022-04-13T22:03:50.975882Z"
    },
    "papermill": {
     "duration": 0.046922,
     "end_time": "2022-04-14T02:15:49.570447",
     "exception": false,
     "start_time": "2022-04-14T02:15:49.523525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(1024,activation='relu')(x) \n",
    "model=Model(inputs=base_model.input,outputs=Dense(1)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce57e18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:15:49.596156Z",
     "iopub.status.busy": "2022-04-14T02:15:49.595340Z",
     "iopub.status.idle": "2022-04-14T08:56:37.919811Z",
     "shell.execute_reply": "2022-04-14T08:56:37.918852Z"
    },
    "papermill": {
     "duration": 24048.339829,
     "end_time": "2022-04-14T08:56:37.919985",
     "exception": false,
     "start_time": "2022-04-14T02:15:49.580156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:15:50.111126: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:15:56.185645: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 150s 554ms/step - loss: 162158112.0000 - rmse: 12734.1318 - val_loss: 700085184.0000 - val_rmse: 26459.1230\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 109s 433ms/step - loss: 73079552.0000 - rmse: 8548.6582 - val_loss: 53703643136.0000 - val_rmse: 231740.4688\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 104s 413ms/step - loss: 55945540.0000 - rmse: 7479.6753 - val_loss: 587316288.0000 - val_rmse: 24234.6094\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 44720768.0000 - rmse: 6687.3589 - val_loss: 332640128.0000 - val_rmse: 18238.4238\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 33955992.0000 - rmse: 5827.1772 - val_loss: 158689264.0000 - val_rmse: 12597.1924\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 30119182.0000 - rmse: 5488.0947 - val_loss: 6613725184.0000 - val_rmse: 81324.8125\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 28906020.0000 - rmse: 5376.4321 - val_loss: 526467968.0000 - val_rmse: 22944.8906\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 28701378.0000 - rmse: 5357.3667 - val_loss: 25948488.0000 - val_rmse: 5093.9658\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 95s 379ms/step - loss: 32677944.0000 - rmse: 5716.4624 - val_loss: 54590724.0000 - val_rmse: 7388.5537\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 97s 387ms/step - loss: 31626320.0000 - rmse: 5623.7285 - val_loss: 10547871.0000 - val_rmse: 3247.7485\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 28764106.0000 - rmse: 5363.2178 - val_loss: 20873466.0000 - val_rmse: 4568.7490\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 25431668.0000 - rmse: 5042.9819 - val_loss: 109383000.0000 - val_rmse: 10458.6328\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 24874344.0000 - rmse: 4987.4185 - val_loss: 3414813696.0000 - val_rmse: 58436.4062\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 24157936.0000 - rmse: 4915.0723 - val_loss: 1005394112.0000 - val_rmse: 31707.9512\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 21609136.0000 - rmse: 4648.5630 - val_loss: 25231440.0000 - val_rmse: 5023.0908\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 18335770.0000 - rmse: 4282.0288 - val_loss: 78773096.0000 - val_rmse: 8875.4209\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 26816802.0000 - rmse: 5178.4941 - val_loss: 695490880.0000 - val_rmse: 26372.1602\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 19474382.0000 - rmse: 4412.9790 - val_loss: 12017895.0000 - val_rmse: 3466.6836\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 18024546.0000 - rmse: 4245.5327 - val_loss: 738390016.0000 - val_rmse: 27173.3320\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 97s 386ms/step - loss: 22262492.0000 - rmse: 4718.3145 - val_loss: 929777600.0000 - val_rmse: 30492.2539\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 14036548.0000 - rmse: 3746.5381 - val_loss: 54908308.0000 - val_rmse: 7410.0142\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 14312105.0000 - rmse: 3783.1343 - val_loss: 1170831360.0000 - val_rmse: 34217.4141\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 17469160.0000 - rmse: 4179.6123 - val_loss: 58541472.0000 - val_rmse: 7651.2397\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 20653666.0000 - rmse: 4544.6304 - val_loss: 138484224.0000 - val_rmse: 11767.9316\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 24481926.0000 - rmse: 4947.9214 - val_loss: 365645280.0000 - val_rmse: 19121.8535\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 23131786.0000 - rmse: 4809.5518 - val_loss: 75601640.0000 - val_rmse: 8694.9199\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 17593700.0000 - rmse: 4194.4844 - val_loss: 106178120.0000 - val_rmse: 10304.2764\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 16940658.0000 - rmse: 4115.9028 - val_loss: 85497448.0000 - val_rmse: 9246.4834\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 15948493.0000 - rmse: 3993.5564 - val_loss: 6833230.5000 - val_rmse: 2614.0449\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 18120330.0000 - rmse: 4256.7979 - val_loss: 57085952.0000 - val_rmse: 7555.5244\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 16740846.0000 - rmse: 4091.5579 - val_loss: 88004952.0000 - val_rmse: 9381.0957\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 15439122.0000 - rmse: 3929.2649 - val_loss: 51391924.0000 - val_rmse: 7168.8159\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 14659358.0000 - rmse: 3828.7542 - val_loss: 8509783.0000 - val_rmse: 2917.1533\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 13638051.0000 - rmse: 3692.9731 - val_loss: 222806336.0000 - val_rmse: 14926.6992\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 12933588.0000 - rmse: 3596.3298 - val_loss: 67591672.0000 - val_rmse: 8221.4150\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 14113255.0000 - rmse: 3756.7612 - val_loss: 183512112.0000 - val_rmse: 13546.6641\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 13155271.0000 - rmse: 3627.0195 - val_loss: 53741548.0000 - val_rmse: 7330.8628\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 12086970.0000 - rmse: 3476.6321 - val_loss: 24883584.0000 - val_rmse: 4988.3447\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 100s 397ms/step - loss: 15644541.0000 - rmse: 3955.3181 - val_loss: 392795232.0000 - val_rmse: 19819.0625\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 13179947.0000 - rmse: 3630.4197 - val_loss: 41571004.0000 - val_rmse: 6447.5581\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 13397405.0000 - rmse: 3660.2466 - val_loss: 92879256.0000 - val_rmse: 9637.3887\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 12363627.0000 - rmse: 3516.1951 - val_loss: 6734419.5000 - val_rmse: 2595.0759\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 14370950.0000 - rmse: 3790.9036 - val_loss: 1216959872.0000 - val_rmse: 34884.9531\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 12688308.0000 - rmse: 3562.0652 - val_loss: 100390376.0000 - val_rmse: 10019.5000\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 13586111.0000 - rmse: 3685.9343 - val_loss: 22352606.0000 - val_rmse: 4727.8545\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 12955556.0000 - rmse: 3599.3828 - val_loss: 56397476.0000 - val_rmse: 7509.8252\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 8850524.0000 - rmse: 2974.9829 - val_loss: 192149264.0000 - val_rmse: 13861.7920\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 12994593.0000 - rmse: 3604.8013 - val_loss: 16503469.0000 - val_rmse: 4062.4463\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 11276854.0000 - rmse: 3358.1028 - val_loss: 80113976.0000 - val_rmse: 8950.6406\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 13657803.0000 - rmse: 3695.6465 - val_loss: 668023872.0000 - val_rmse: 25846.1582\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 10743323.0000 - rmse: 3277.7009 - val_loss: 49008532.0000 - val_rmse: 7000.6094\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 12553727.0000 - rmse: 3543.1240 - val_loss: 822216000.0000 - val_rmse: 28674.3086\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 12742784.0000 - rmse: 3569.7036 - val_loss: 158776816.0000 - val_rmse: 12600.6670\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 10628033.0000 - rmse: 3260.0664 - val_loss: 18172642.0000 - val_rmse: 4262.9380\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 9554780.0000 - rmse: 3091.0808 - val_loss: 305956960.0000 - val_rmse: 17491.6250\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 99s 397ms/step - loss: 10655242.0000 - rmse: 3264.2368 - val_loss: 40903348.0000 - val_rmse: 6395.5728\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 12152926.0000 - rmse: 3486.1047 - val_loss: 2133716096.0000 - val_rmse: 46192.1641\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 12104758.0000 - rmse: 3479.1892 - val_loss: 63192212.0000 - val_rmse: 7949.3530\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 10961071.0000 - rmse: 3310.7507 - val_loss: 4522876.5000 - val_rmse: 2126.7056\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 97s 388ms/step - loss: 9996182.0000 - rmse: 3161.6738 - val_loss: 62017460.0000 - val_rmse: 7875.1167\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 10297672.0000 - rmse: 3208.9985 - val_loss: 137383568.0000 - val_rmse: 11721.0732\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 9186275.0000 - rmse: 3030.8867 - val_loss: 15150340.0000 - val_rmse: 3892.3438\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 10809314.0000 - rmse: 3287.7522 - val_loss: 74061528.0000 - val_rmse: 8605.9004\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 9629525.0000 - rmse: 3103.1477 - val_loss: 9207626.0000 - val_rmse: 3034.4070\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 10551281.0000 - rmse: 3248.2734 - val_loss: 91239512.0000 - val_rmse: 9551.9375\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 9616431.0000 - rmse: 3101.0371 - val_loss: 66768768.0000 - val_rmse: 8171.2158\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 10387473.0000 - rmse: 3222.9602 - val_loss: 1685731456.0000 - val_rmse: 41057.6602\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 10827844.0000 - rmse: 3290.5688 - val_loss: 5888825.5000 - val_rmse: 2426.6902\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 9494544.0000 - rmse: 3081.3218 - val_loss: 41617556.0000 - val_rmse: 6451.1670\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 10051746.0000 - rmse: 3170.4490 - val_loss: 50052260.0000 - val_rmse: 7074.7622\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 9299768.0000 - rmse: 3049.5520 - val_loss: 74383784.0000 - val_rmse: 8624.6035\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 9160535.0000 - rmse: 3026.6377 - val_loss: 114093176.0000 - val_rmse: 10681.4404\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 9803915.0000 - rmse: 3131.1204 - val_loss: 747347136.0000 - val_rmse: 27337.6504\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 11254407.0000 - rmse: 3354.7588 - val_loss: 8526326.0000 - val_rmse: 2919.9873\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 9326762.0000 - rmse: 3053.9749 - val_loss: 66157008.0000 - val_rmse: 8133.6958\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 6165473.5000 - rmse: 2483.0371 - val_loss: 4888577.0000 - val_rmse: 2211.0127\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 9100209.0000 - rmse: 3016.6553 - val_loss: 27964904.0000 - val_rmse: 5288.1855\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 7890084.5000 - rmse: 2808.9294 - val_loss: 14342844.0000 - val_rmse: 3787.1948\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 6680756.5000 - rmse: 2584.7158 - val_loss: 65158340.0000 - val_rmse: 8072.0718\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 8996253.0000 - rmse: 2999.3755 - val_loss: 3521819.0000 - val_rmse: 1876.6510\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 9179245.0000 - rmse: 3029.7268 - val_loss: 18674338.0000 - val_rmse: 4321.3813\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 9299469.0000 - rmse: 3049.5032 - val_loss: 29748710.0000 - val_rmse: 5454.2378\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 7635012.0000 - rmse: 2763.1526 - val_loss: 19083378.0000 - val_rmse: 4368.4526\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 9552178.0000 - rmse: 3090.6599 - val_loss: 4129526.7500 - val_rmse: 2032.1237\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 8295464.0000 - rmse: 2880.1848 - val_loss: 58859180.0000 - val_rmse: 7671.9736\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 103s 414ms/step - loss: 6343785.0000 - rmse: 2518.6873 - val_loss: 171206912.0000 - val_rmse: 13084.6055\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 10350453.0000 - rmse: 3217.2119 - val_loss: 13197813.0000 - val_rmse: 3632.8794\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 8448623.0000 - rmse: 2906.6516 - val_loss: 43451376.0000 - val_rmse: 6591.7656\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 104s 415ms/step - loss: 10090047.0000 - rmse: 3176.4834 - val_loss: 253559088.0000 - val_rmse: 15923.5391\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 6927183.0000 - rmse: 2631.9541 - val_loss: 38309552.0000 - val_rmse: 6189.4712\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 6697629.5000 - rmse: 2587.9778 - val_loss: 213603792.0000 - val_rmse: 14615.1904\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 8301366.0000 - rmse: 2881.2092 - val_loss: 4143887.2500 - val_rmse: 2035.6541\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 98s 394ms/step - loss: 7580232.5000 - rmse: 2753.2222 - val_loss: 24484840.0000 - val_rmse: 4948.2158\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 7185261.0000 - rmse: 2680.5337 - val_loss: 8814635.0000 - val_rmse: 2968.9451\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 104s 417ms/step - loss: 7655876.5000 - rmse: 2766.9255 - val_loss: 40668136.0000 - val_rmse: 6377.1572\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 6489040.5000 - rmse: 2547.3596 - val_loss: 77954208.0000 - val_rmse: 8829.1680\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 99s 397ms/step - loss: 8669196.0000 - rmse: 2944.3499 - val_loss: 6942770.5000 - val_rmse: 2634.9138\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 7536152.5000 - rmse: 2745.2053 - val_loss: 299459680.0000 - val_rmse: 17304.9043\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 5897986.5000 - rmse: 2428.5771 - val_loss: 44681612.0000 - val_rmse: 6684.4307\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 6753623.5000 - rmse: 2598.7734 - val_loss: 16222479.0000 - val_rmse: 4027.7139\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 5852192.5000 - rmse: 2419.1306 - val_loss: 51014140.0000 - val_rmse: 7142.4185\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 6042792.5000 - rmse: 2458.2092 - val_loss: 39289248.0000 - val_rmse: 6268.1138\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 6800972.5000 - rmse: 2607.8674 - val_loss: 28642582.0000 - val_rmse: 5351.8765\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 94s 373ms/step - loss: 8230974.0000 - rmse: 2868.9675 - val_loss: 5496126.0000 - val_rmse: 2344.3818\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 5644161.0000 - rmse: 2375.7444 - val_loss: 6108508.0000 - val_rmse: 2471.5396\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 5948759.5000 - rmse: 2439.0078 - val_loss: 32927282.0000 - val_rmse: 5738.2300\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 99s 397ms/step - loss: 6464631.5000 - rmse: 2542.5640 - val_loss: 2793261.2500 - val_rmse: 1671.3053\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 99s 397ms/step - loss: 6703227.0000 - rmse: 2589.0591 - val_loss: 38061240.0000 - val_rmse: 6169.3794\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 6814301.5000 - rmse: 2610.4216 - val_loss: 42259888.0000 - val_rmse: 6500.7607\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 5692672.5000 - rmse: 2385.9321 - val_loss: 24374360.0000 - val_rmse: 4937.0396\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 5061471.0000 - rmse: 2249.7712 - val_loss: 4333319.5000 - val_rmse: 2081.6626\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 9278067.0000 - rmse: 3045.9919 - val_loss: 3546796.7500 - val_rmse: 1883.2941\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 6705851.0000 - rmse: 2589.5657 - val_loss: 17298598.0000 - val_rmse: 4159.1582\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 6017479.5000 - rmse: 2453.0552 - val_loss: 16444380.0000 - val_rmse: 4055.1670\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 7793680.5000 - rmse: 2791.7163 - val_loss: 37422212.0000 - val_rmse: 6117.3696\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 5999999.0000 - rmse: 2449.4895 - val_loss: 500187648.0000 - val_rmse: 22364.8750\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 95s 379ms/step - loss: 6740472.5000 - rmse: 2596.2419 - val_loss: 19167372.0000 - val_rmse: 4378.0557\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 5957918.0000 - rmse: 2440.8848 - val_loss: 2216349.7500 - val_rmse: 1488.7410\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 6806207.0000 - rmse: 2608.8708 - val_loss: 16401364.0000 - val_rmse: 4049.8599\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 5845043.5000 - rmse: 2417.6526 - val_loss: 6013458.0000 - val_rmse: 2452.2354\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 94s 374ms/step - loss: 5364210.0000 - rmse: 2316.0764 - val_loss: 1818010.3750 - val_rmse: 1348.3362\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 5009593.5000 - rmse: 2238.2122 - val_loss: 33405130.0000 - val_rmse: 5779.7173\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 6769720.5000 - rmse: 2601.8687 - val_loss: 538765696.0000 - val_rmse: 23211.3262\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 8357793.0000 - rmse: 2890.9849 - val_loss: 16817898.0000 - val_rmse: 4100.9629\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 5065539.0000 - rmse: 2250.6753 - val_loss: 4883485.0000 - val_rmse: 2209.8608\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 6530408.0000 - rmse: 2555.4663 - val_loss: 20164480.0000 - val_rmse: 4490.4878\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 5314749.5000 - rmse: 2305.3740 - val_loss: 10709503.0000 - val_rmse: 3272.5376\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 5156953.5000 - rmse: 2270.8926 - val_loss: 2950414.7500 - val_rmse: 1717.6771\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 5080293.0000 - rmse: 2253.9504 - val_loss: 3124528.2500 - val_rmse: 1767.6335\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 5881342.0000 - rmse: 2425.1479 - val_loss: 32477590.0000 - val_rmse: 5698.9111\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 5600574.0000 - rmse: 2366.5532 - val_loss: 28614642.0000 - val_rmse: 5349.2656\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 6243969.5000 - rmse: 2498.7937 - val_loss: 78323608.0000 - val_rmse: 8850.0625\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 6502747.0000 - rmse: 2550.0483 - val_loss: 72295008.0000 - val_rmse: 8502.6475\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 6409813.0000 - rmse: 2531.7607 - val_loss: 23550522.0000 - val_rmse: 4852.8882\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 4726609.5000 - rmse: 2174.0767 - val_loss: 1785391.5000 - val_rmse: 1336.1854\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 4979175.5000 - rmse: 2231.4067 - val_loss: 3419414.7500 - val_rmse: 1849.1660\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 102s 410ms/step - loss: 6012417.0000 - rmse: 2452.0229 - val_loss: 4258386.5000 - val_rmse: 2063.5859\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 4710805.5000 - rmse: 2170.4390 - val_loss: 43781768.0000 - val_rmse: 6616.7793\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 4478411.5000 - rmse: 2116.2258 - val_loss: 22979694.0000 - val_rmse: 4793.7139\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 5211591.5000 - rmse: 2282.8911 - val_loss: 29940838.0000 - val_rmse: 5471.8223\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 6310998.5000 - rmse: 2512.1702 - val_loss: 20986012.0000 - val_rmse: 4581.0493\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 4272278.5000 - rmse: 2066.9490 - val_loss: 27046232.0000 - val_rmse: 5200.5991\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 5099540.0000 - rmse: 2258.2161 - val_loss: 3132235.0000 - val_rmse: 1769.8121\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 3415021.2500 - rmse: 1847.9777 - val_loss: 35424864.0000 - val_rmse: 5951.8789\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 5623270.0000 - rmse: 2371.3435 - val_loss: 27529390.0000 - val_rmse: 5246.8457\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 4023866.7500 - rmse: 2005.9578 - val_loss: 11874184.0000 - val_rmse: 3445.8938\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 5343385.0000 - rmse: 2311.5764 - val_loss: 45395732.0000 - val_rmse: 6737.6353\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 4690810.0000 - rmse: 2165.8279 - val_loss: 5862062.5000 - val_rmse: 2421.1697\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 5655971.0000 - rmse: 2378.2285 - val_loss: 15342908.0000 - val_rmse: 3917.0024\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 4497616.0000 - rmse: 2120.7583 - val_loss: 18558150.0000 - val_rmse: 4307.9170\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 106s 422ms/step - loss: 4539223.5000 - rmse: 2130.5454 - val_loss: 15244767.0000 - val_rmse: 3904.4548\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 4683811.5000 - rmse: 2164.2114 - val_loss: 84626472.0000 - val_rmse: 9199.2646\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 104s 417ms/step - loss: 5142982.5000 - rmse: 2267.8145 - val_loss: 3559731.2500 - val_rmse: 1886.7250\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 6626913.0000 - rmse: 2574.2791 - val_loss: 94136248.0000 - val_rmse: 9702.3838\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 4073785.7500 - rmse: 2018.3622 - val_loss: 7077760.0000 - val_rmse: 2660.4060\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 5047428.0000 - rmse: 2246.6482 - val_loss: 23663962.0000 - val_rmse: 4864.5620\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 92s 368ms/step - loss: 5418109.0000 - rmse: 2327.6831 - val_loss: 100742408.0000 - val_rmse: 10037.0518\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 4605325.0000 - rmse: 2146.0022 - val_loss: 68787864.0000 - val_rmse: 8293.8447\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 102s 405ms/step - loss: 4471354.0000 - rmse: 2114.5576 - val_loss: 2196118.2500 - val_rmse: 1481.9305\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 103s 413ms/step - loss: 4886031.5000 - rmse: 2210.4370 - val_loss: 10208539.0000 - val_rmse: 3195.0803\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 4411188.5000 - rmse: 2100.2830 - val_loss: 48570012.0000 - val_rmse: 6969.2188\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 4868661.5000 - rmse: 2206.5044 - val_loss: 39759936.0000 - val_rmse: 6305.5479\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 4987457.5000 - rmse: 2233.2617 - val_loss: 25989214.0000 - val_rmse: 5097.9619\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 4030146.0000 - rmse: 2007.5223 - val_loss: 17236608.0000 - val_rmse: 4151.6992\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 93s 374ms/step - loss: 6258807.0000 - rmse: 2501.7607 - val_loss: 4360666.0000 - val_rmse: 2088.2207\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 6071279.5000 - rmse: 2463.9966 - val_loss: 24786842.0000 - val_rmse: 4978.6387\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 94s 374ms/step - loss: 4438600.0000 - rmse: 2106.7986 - val_loss: 8533139.0000 - val_rmse: 2921.1538\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 4436792.0000 - rmse: 2106.3694 - val_loss: 29165422.0000 - val_rmse: 5400.5020\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 4325340.0000 - rmse: 2079.7451 - val_loss: 2804624.2500 - val_rmse: 1674.7013\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 5229086.5000 - rmse: 2286.7195 - val_loss: 4320504.0000 - val_rmse: 2078.5823\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 102s 410ms/step - loss: 3623289.7500 - rmse: 1903.4941 - val_loss: 41358188.0000 - val_rmse: 6431.0332\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 7184029.0000 - rmse: 2680.3040 - val_loss: 3865006.0000 - val_rmse: 1965.9618\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 3510244.2500 - rmse: 1873.5646 - val_loss: 20184798.0000 - val_rmse: 4492.7495\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 4866752.5000 - rmse: 2206.0718 - val_loss: 13629988.0000 - val_rmse: 3691.8813\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 3872757.2500 - rmse: 1967.9323 - val_loss: 21224358.0000 - val_rmse: 4606.9902\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 5066855.5000 - rmse: 2250.9678 - val_loss: 22139474.0000 - val_rmse: 4705.2603\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 3805382.5000 - rmse: 1950.7390 - val_loss: 15298968.0000 - val_rmse: 3911.3894\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 104s 414ms/step - loss: 3338050.5000 - rmse: 1827.0332 - val_loss: 2877801.2500 - val_rmse: 1696.4083\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 5472087.0000 - rmse: 2339.2493 - val_loss: 4403723.5000 - val_rmse: 2098.5051\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 4011343.0000 - rmse: 2002.8337 - val_loss: 7526614.5000 - val_rmse: 2743.4675\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 4195788.0000 - rmse: 2048.3623 - val_loss: 28918486.0000 - val_rmse: 5377.5913\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 4251657.5000 - rmse: 2061.9548 - val_loss: 108493120.0000 - val_rmse: 10416.0029\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 4057576.7500 - rmse: 2014.3428 - val_loss: 23882440.0000 - val_rmse: 4886.9663\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 3348948.2500 - rmse: 1830.0132 - val_loss: 2394022.7500 - val_rmse: 1547.2629\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 104s 415ms/step - loss: 4155139.5000 - rmse: 2038.4159 - val_loss: 25858680.0000 - val_rmse: 5085.1431\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00185: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "# Important, calculate a valid step size for the validation dataset\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='adam', metrics=[RootMeanSquaredError(name=\"rmse\")])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator, epochs=200, steps_per_epoch=250, \n",
    "                    validation_data = val_generator, callbacks=[monitor],\n",
    "                    verbose = 1, validation_steps=STEP_SIZE_VALID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a7281d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:57:08.037302Z",
     "iopub.status.busy": "2022-04-14T08:57:08.036485Z",
     "iopub.status.idle": "2022-04-14T08:58:15.230847Z",
     "shell.execute_reply": "2022-04-14T08:58:15.230357Z"
    },
    "papermill": {
     "duration": 82.457662,
     "end_time": "2022-04-14T08:58:15.230991",
     "exception": false,
     "start_time": "2022-04-14T08:56:52.773329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4005 validated image filenames.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16019</td>\n",
       "      <td>7646.633301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16020</td>\n",
       "      <td>57419.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16021</td>\n",
       "      <td>11251.871094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16022</td>\n",
       "      <td>6244.526367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16023</td>\n",
       "      <td>14903.236328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>20019</td>\n",
       "      <td>7500.638672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>20020</td>\n",
       "      <td>9795.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>20021</td>\n",
       "      <td>9906.341797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>20022</td>\n",
       "      <td>15410.347656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>20023</td>\n",
       "      <td>11343.986328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4005 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      distance\n",
       "0     16019   7646.633301\n",
       "1     16020  57419.515625\n",
       "2     16021  11251.871094\n",
       "3     16022   6244.526367\n",
       "4     16023  14903.236328\n",
       "...     ...           ...\n",
       "4000  20019   7500.638672\n",
       "4001  20020   9795.900391\n",
       "4002  20021   9906.341797\n",
       "4003  20022  15410.347656\n",
       "4004  20023  11343.986328\n",
       "\n",
       "[4005 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "submit_generator = submit_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        class_mode=None)\n",
    "\n",
    "submit_generator.reset()\n",
    "pred = model.predict(submit_generator,steps=len(df_test))\n",
    "df_submit = pd.DataFrame({\"id\":df_test['id'],'distance':pred[:,0].flatten()})\n",
    "df_submit.to_csv(\"submission.csv\",index = False)\n",
    "df_submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24186.586383,
   "end_time": "2022-04-14T08:58:33.784051",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-14T02:15:27.197668",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
